\documentclass[12pt,a4paper]{article}
\usepackage{epsf}
%\input{amssym.def}
%
\title{Short manual for the JDQZ-package}

\author{Diederik~R.\ Fokkema%
\footnotemark[1]\hspace{1ex}
    \and
  Martin~B.\ van Gijzen\footnotemark[3]}

\def\BA{{\bf A}}\def\BB{{\bf B}}
\def\BW{{\bf W}}
\def\Bx{{\bf x}}\def\Br{{\bf r}}
\def\Bv{{\bf v}}\def\Bw{{\bf w}}
\begin{document}
\maketitle
 \renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{ ISE Integrated Systems Engineering AG,
  Technopark Z\"urich, Technoparkstrasse 1, CH-8005 Z\"urich, Switzerland.
  E-mail: {\tt fokkema@@ise.ch}.}
\footnotetext[3]{ Departement of Mathematics, Utrecht University,
   P.O.~Box 80.010, NL-3508 TA~~Utrecht, The Netherlands.
   E-mail: {\tt sleijpen@@math.ruu.nl, vorst@@math.ruu.nl}.}

 \renewcommand{\thefootnote}{\arabic{footnote}}

\section{Introduction}
The JDQZ algorithm computes a number of eigenpairs near a target value of the 
generalized eigen problem
\begin{equation}
  \beta \BA \Bx = \alpha \BB \Bx .
  \label{eq:system}
\end{equation}
The algorithm is described in the paper
"Jacobi-Davidson style QR and QZ algorithms for the reduction of matrix pencils" by D.R. Fokkema, G.L.G. Sleijpen, and H.A. van der Vorst \cite{jdqz}. 
The paper can be obtained from the homepage of Gerard Sleijpen 
(http://www.math.ruu.nl/people/sleijpen/) or from the homepage of Henk van der 
Vorst (http://www.math.ruu.nl/people/vorst/). 
This package is a Fortran 77 implementation of the algorithm.
The code has been developed
by Diederik Fokkema and has been modified by Martin van Gijzen and is currently maintained by 
Wim Bomhof. \\
Permission to copy all or part of this code is granted, provided
that the copies are not made or distributed for resale.\\
THE CODE IS PROVIDED ON AN "AS IS" BASIS.  THE AUTHORS PROVIDE NO
WARRANTY WHATSOEVER, EITHER EXPRESSED OR IMPLIED, REGARDING THE WORK,
INCLUDING WARRANTIES WITH RESPECT TO ITS MERCHANTABILITY OR FITNESS
FOR ANY PARTICULAR PURPOSE.\\
\section{Obtaining the code}
To obtain the code you can send an e-mail to: bomhof@math.ruu.nl.
In return you will receive a uuencoded, gziped and tared file.
Save this file as jdqz.tar.gz.uue.
You can install the code by typing the following commands:\\

\indent
{\tt uudecode jdqz.tar.gz.uue}

\indent
{\tt gunzip jdqz.tar.gz}

\indent
{\tt tar xvf jdqz.tar}\\

This has created a directory {\tt jdqz}, with two subdirectories {\tt jdlib}
and {\tt jdtest}. You can find this manual in the directory {\tt jdqz}, the
code is in the subdirectories. Makefiles are supplied, so if the necessary
libraries are present, in particular LAPACK, typing {\tt make} should 
make the jdqz-library.

\section{Usage of the package}
The package is written in Fortran 77 and uses the double complex data-type.
It calls routines from the LAPACK and BLAS libraries. 
These libraries are installed
on many machines. LAPACK and BLAS routines can also be obtained from Netlib
(http://www.netlib.org/index.html). 
The directory jdlib contains the actual JDQZ-code, the directory jdtest
contains some examples that may be of help in using the code.
\subsection{User supplied subroutines}
The user has to supply three problem dependent routines: one for the
multiplication of a vector with the operator $\BA$, one for multiplication
with $\BB$, and one for performing the preconditioning operation. The
subroutine to multiply with $\BA$ must be called {\tt AMUL} and must have the
following header:
\begin{verbatim}

      subroutine AMUL( n, q, r )
c...............................................
c...     Subroutine to compute r = Aq
c...............................................
      integer        n
      double complex q(n), r(n)

\end{verbatim}
{\tt q} is the input vector, {\tt r} the output vector. {\tt n} is the 
dimension of the problem. The
subroutine to multiply with $\BB$ must be called {\tt BMUL} and must have the
following header:
\begin{verbatim}

      subroutine BMUL( n, q, r )
c...............................................
c...     Subroutine to compute r = Bq
c...............................................
      integer        n
      double complex q(n), r(n)

\end{verbatim}
Finally, the routine to perform the preconditioning operation must be
called {\tt PRECON} and must have the header
\begin{verbatim}

      subroutine PRECON( n, q )
c...............................................
c...     Subroutine to compute q = K^-1 q
c...............................................
      integer        n
      double complex q(n)

\end{verbatim}
The preconditioning matrix should be an approximation of the matrix
$\BA - \tau \BB$, with $\tau$ the prechosen target value. Preconditioning 
within the JDQZ algorithm is described in section 3.4 of \cite{jdqz}.
Preconditioning is not essential for the correct behavior of the algorithm.
It should improve the rate of convergence, but leaving the vector {\tt q}
untouched should have no influence on the correctness of the results.

Note that data for the matrices, 
like the nonzero coeffcients and their indices, should be passed via 
{\tt common} blocks, not via the parameter lists. 
\newpage
\subsection{Calling JDQZ}
JDQZ itself can be called with the statement
\begin{verbatim}
 
      call JDQZ( alpha, beta, eivec, wanted, n, target, eps,
     $     kmax, jmax, jmin, method, m, l, mxmv, maxstep,
     $     lock, order, testspace, zwork, lwork )

\end{verbatim}
The parameters must be of the following data types:

\noindent
\begin{tabular}{lp{10cm}}
{\tt alpha, beta}& double complex array, size {\tt jmax}\\
{\tt eivec}& two dimensional double complex array, size {\tt n $\times$ kmax}\\
{\tt wanted}& logical, scalar\\
{\tt n}& integer, scalar\\
{\tt target}& double complex, scalar\\
{\tt eps}& double precision, scalar\\
{\tt kmax}& integer, scalar\\
{\tt jmax}& integer, scalar\\
{\tt jmin}& integer, scalar\\
{\tt method}& integer, scalar\\
{\tt m}& integer, scalar\\
{\tt l}& integer, scalar\\
{\tt mxmv}& integer, scalar\\
{\tt maxstep}& integer, scalar\\
{\tt lock}& double precision, scalar\\
{\tt order}& integer, scalar\\
{\tt testspace}& integer, scalar\\
{\tt zwork}& two dimensional double complex array, size {\tt n $\times$ lwork}\\
{\tt lwork}& integer, scalar
\end{tabular}\\

\newpage
The meaning of most of the parameters can be found in \cite{jdqz} and we will
refer to the appropriate section if possible.\\

\noindent
\begin{tabular}{lp{10cm}}
{\tt alpha, beta}& Obvious from equation (\ref{eq:system}) \\
{\tt wanted}& Compute the converged eigenvectors (if {\tt wanted = .true.})\\
{\tt eivec}& Converged eigenvectors if {\tt wanted = .true.}, else converged 
Schur vectors\\
{\tt n}& The size of the problem\\
{\tt target}& The value near which the eigenvalues are sought\\
{\tt eps}& Tolerance of the eigensolutions, $\| \beta \BA\Bx - \alpha \BB\Bx \| / | \alpha/\beta | < \epsilon$ \\
{\tt kmax}& Number of wanted eigensolutions,
on output: number of converged eigenpairs\\
{\tt jmax}& Maximum size of the search space\\
{\tt jmin}& Minimum size of the search space\\
{\tt method}& Linear equation solver:\\
\indent
1: & GMRES$_m$, \cite{gmres}\\
\indent
2: & BiCGstab($\ell$), \cite{cgstab}\\
{\tt m}& Maximum dimension of searchspace of GMRES$_m$ \\
{\tt l}& Degree of GMRES-polynomial in Bi-CGstab($\ell$)\\
{\tt mxmv}& Maximum number of matrix-vector multiplications in GMRES$_m$
or BiCGstab($\ell$)\\
{\tt maxstep}& Maximum number of Jacobi-Davidson iterations\\
{\tt lock}& Tracking parameter (section 2.5.1)\\
{\tt order}& Selection criterion for Ritz values:\\
\indent
0:& nearest to {\tt target}\\
\indent
-1:& smallest real part\\
\indent
1:& largest real part\\
\indent
-2:& smallest imaginary part\\
\indent
2:& largest imaginary part\\
{\tt testspace}& Determines how to expand the testspace $\BW$\\
\indent
1:& $\Bw =$ "Standard Petrov" $\times \Bv$ (Section 3.1.1)\\
\indent
2:& $\Bw =$ "Standard 'variable' Petrov" $\times \Bv$ (Section 3.1.2)\\
\indent
3:& $\Bw =$ "Harmonic Petrov" $\times \Bv$ (Section 3.5.1)\\
{\tt zwork}& Workspace\\
{\tt lwork}& Size of workspace, $>= 4+m+5{\tt jmax}+3{\tt kmax}$ if GMRES$_m$ is used, 
$>= 10+6{\ell}+5{\tt jmax}+3{\tt kmax}$ if Bi-CGstab($\ell$) is used.\\
\end{tabular}

\section{Guidelines for chosing the parameters.}
In this section we will try to give some sound guidelines how to choose the
parameters. Optimal parameters are of course problem and system dependent, but
we will give "on average" reasonable values, based on practical experience.

\begin{tabular}{lp{10cm}}
{\tt eps}& $10^{-9}$, don't take it too large. A relatively large value for
{\tt eps} may
cause problems when computing many eigen solutions. Moreover, 
convergence from moderate to high accuracy is fast.\\
{\tt kmax}& It may be wise to take {\tt kmax} a bit larger than the actual 
number of eigensolutions you want, to avoid missing one\\
{\tt jmax}& very problem and memory dependent, reasonable value: $3 \times {\tt kmax}$ with a minimum of 20\\
{\tt jmin}& $2 \times {\tt kmax}$\\
{\tt method}& 2 (BiCGstab($\ell$))\\
{\tt m}& 30\\
{\tt l}& 2\\
{\tt mxmv}& Very problem dependent, any value in the range 5-100 is reasonable.
Suggestion: 100\\
{\tt maxstep}& 1000\\
{\tt lock}& Take it small to avoid missing eigensolutions, eg. ${\tt lock} = 10^{-9}$.\\
{\tt testspace}& 3 if a reasonable value for {\tt target} is known, else take 2
\end{tabular}

\section{Example}
In this section we will illustrate the usage of the code by a very simple
example. The example can be found in the directory jdtest. For $\BA$ and $\BB$ we
take diagonal matrices. The action of $\BA$ and $\BB$ is described by the 
following piece of Fortran code:
\begin{verbatim}

      subroutine AMUL( n, q, r )
c...............................................
c...     Subroutine to compute r = Aq
c...............................................
      integer        n, i
      double complex q(n), r(n)
c
      do i = 1, n
         r(i) = i*q(i)
      end do
c
      end

      subroutine BMUL( n, q, r )
c...............................................
c...     Subroutine to compute r = Bq
c...............................................
      integer        n, i
      double complex q(n), r(n)
c
      do i = 1, n
         r(i) = q(i)/i
      end do
c
      end

\end{verbatim}
Obviously, we have for the eigenvalues $\alpha / \beta$ of (\ref{eq:system})
\begin{equation}
   \alpha / \beta = i^2  ~~( i = 1, \cdots, n ) 
\end{equation}
We want to compute the five eigenvalues closest to 31, so {\tt target = 31}, 
and {\tt kmax = 5}. The preconditioning operation should mimic the action of
the matrix $(\BA - \tau \BB)^{-1}$. Since we are dealing with diagonal matrices 
we can take the exact inverse. The preconditioning operation is then 
described by
\begin{verbatim}

      subroutine PRECON( n, q )
c...............................................
c...     Subroutine to compute q = K^-1 q
c...............................................
      integer        n, i
      double complex q(n)
c
      do i = 1, n
         q(i) = i*q(i)/(i*i-31)
      end do
c
      end

\end{verbatim}
We take for the problem size {\tt n = 100}. We are searching near a target, hence {\tt order = 0}.
For the rest of the parameters we take the values suggested in the previous section:

\begin{tabular}{lp{10cm}}
{\tt eps}& $10^{-9}$\\
{\tt jmax}& 20\\
{\tt jmin}& 10\\
{\tt method}& 2\\
{\tt m}& 30 (does not matter, is not used)\\
{\tt l}& 2\\
{\tt mxmv}& 100\\
{\tt maxstep}& 1000\\
{\tt lock}& $10^{-9}$.\\
{\tt testspace}& 3
\end{tabular}

At the end we want to compute to compute the norms of the residuals
\begin{equation}
   \| \Br_i \| = \| \beta_i \BA \Bx_i - \alpha_i \BB \Bx_i \|
\end{equation}
and therefore need the eigenvectors. Hence {\tt wanted = .true.}.
The parameter {\tt lwork} is set to 137, the minimum allowed for the choice
of parameters. The following piece of code
\begin{verbatim}

      call JDQZ(alpha, beta, eivec, wanted, n, target, eps,
     $     kmax, jmax, jmin,
     $     method, m, l, maxnmv, maxstep,
     $     lock, order, testspace, zwork, lwork )
c
      elapse = etime( tarray )
c
c...     Compute the norms of the residuals:
c...     tmp is a double complex array of size n
      do j = 1, kmax
         call amul  ( n, eivec(1,j), residu )
         call zscal ( n, beta(j), residu, 1)
         call bmul  ( n, eivec(1,j), tmp )
         call zaxpy( n, -alpha(j), tmp, 1, residu, 1 )
         print '("lambda(",i2,"): (",1p,e11.4,",",e11.4,
     $        " )")', j,alpha(j)/beta(j)
         print '(a30,d13.6)', '||beta Ax - alpha Bx||:',
     $          dznrm2( n, residu, 1 )
      end do
      write(*,10) tarray(1), elapse
c
   10 format(1x,'END JDQZ AFTER ',f6.2,' SEC. CPU-TIME AND ', f6.2,
     $       ' SEC. ELAPSED TIME' )

\end{verbatim}
gives as output
\begin{verbatim}

lambda( 1): ( 3.6000E+01, 0.0000E+00 )
       ||beta Ax - alpha Bx||: 0.109282D-10
lambda( 2): ( 2.5000E+01, 0.0000E+00 )
       ||beta Ax - alpha Bx||: 0.200064D-09
lambda( 3): ( 1.6000E+01, 0.0000E+00 )
       ||beta Ax - alpha Bx||: 0.207683D-10
lambda( 4): ( 4.9000E+01, 0.0000E+00 )
       ||beta Ax - alpha Bx||: 0.373422D-09
lambda( 5): ( 9.0000E+00, 0.0000E+00 )
       ||beta Ax - alpha Bx||: 0.526224D-10
END JDQZ AFTER   0.84 SEC. CPU-TIME AND   0.96 SEC. ELAPSED TIME

\end{verbatim}
The preconditioning reduces the computing time considerably. JDQZ without
preconditioning gives the same eigenvalues, but for the timing it gives
\begin{verbatim}

END JDQZ AFTER   3.97 SEC. CPU-TIME AND   4.13 SEC. ELAPSED TIME

\end{verbatim}
hence, preconditioning gives a reduction of the computing time of about
a factor four for this example. 

\begin{thebibliography}{9}

\bibitem{jdqz}
D.R. Fokkema, G.L.G. Sleijpen, and H.A. van der Vorst, 
\newblock {\em Jacobi-Davidson style QR and QZ algorithms for the partial reduction of matrix Pencils.}
\newblock Preprint 941, Department of Mathematics, Utrecht University, January, 1996.

\bibitem{gmres}
Y.~Saad and M.H. Schultz.
\newblock {GMRES}: A generalized minimum residual algorithm for solving nonsymmetric linear systems.
\newblock {\em {SIAM} J. Sci. Statist. Comput.}, 7:856--869, 1986.

\bibitem{cgstab}
G.L.G.~Sleijpen and D.R. Fokkema.
\newblock {BiCGstab($\ell$)} for linear equations involving matrices with complex spectrum.
\newblock {\em ETNA} 1:11--32, 1994

\end{thebibliography}
\end{document}
